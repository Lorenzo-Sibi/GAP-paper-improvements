{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac38016c-7f0f-4c45-8c06-588afdcb8fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd26cc80-5a84-48ab-ac33-715a101f61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from itertools import product\n",
    "import wandb\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f97320-5fd2-436a-8ef1-6d85957407e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_user = 'sisaman'\n",
    "wandb_project = 'GAPTEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d735c43-3800-45a8-bec1-a57573459325",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommandBuilder:\n",
    "    def __init__(self, subcommand):\n",
    "        self.subcommand = subcommand\n",
    "    \n",
    "    def build(self, **params):      \n",
    "        for key, value in params.items():\n",
    "            if not (isinstance(value, list) or isinstance(value, tuple)):\n",
    "                params[key] = (value,)\n",
    "        \n",
    "        cmd_list = []\n",
    "        configs = self.product_dict(params)\n",
    "\n",
    "        for config in configs:\n",
    "            options = ' '.join([f' --{param} {value} ' for param, value in config.items()])\n",
    "            command = f'python train.py {self.subcommand} {options}'\n",
    "            command = ' '.join(command.split())\n",
    "            cmd_list.append(command)\n",
    "\n",
    "        return cmd_list\n",
    "\n",
    "    @staticmethod\n",
    "    def product_dict(params):\n",
    "        keys = params.keys()\n",
    "        vals = params.values()\n",
    "        for instance in product(*vals):\n",
    "            yield dict(zip(keys, instance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd51b9-3ff7-42ff-88f8-9fbf7bc5f675",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4e925c-8c31-4491-86fa-40387b9b4489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583cd00ecb084467950a231a34adb48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fa844764f143c286b9a85a7a293b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find project GAPTEST\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total runs:  1098\n",
      "finished:    0\n",
      "new:         1098\n"
     ]
    }
   ],
   "source": [
    "# DEFAULT PARAMS\n",
    "dataset=['reddit', 'amazon', 'facebook']\n",
    "epsilon={\n",
    "    'edge': list(range(1,10,2)),\n",
    "    'node': list(range(5,30,5))\n",
    "}\n",
    "hops=[1,2,3,4,5]\n",
    "max_degree = {\n",
    "    'edge': -1,\n",
    "    'node': {\n",
    "        'facebook': {\n",
    "            'standard': [10,20,50,100,200],\n",
    "            'extended': [10,20,50,100,200],\n",
    "        },\n",
    "        'reddit': {\n",
    "            'standard': [50,100,200,300,400],\n",
    "            'extended': [50,100,200,300,400],\n",
    "        },\n",
    "        'amazon': {\n",
    "            'standard': [10,20,50,100,200],\n",
    "            'extended': [10,20,50,100,200],\n",
    "        },\n",
    "    }\n",
    "}\n",
    "hidden_dim=[16]\n",
    "encoder_layers=2\n",
    "pre_layers=1\n",
    "post_layers=1\n",
    "combine='cat'\n",
    "activation='selu'\n",
    "dropout=0\n",
    "batch_norm=True\n",
    "optimizer='adam'\n",
    "learning_rate=0.01,\n",
    "weight_decay=0,\n",
    "pre_epochs = {\n",
    "    'edge': 100,\n",
    "    'node': 10,\n",
    "}\n",
    "epochs = {\n",
    "    'edge': 100,\n",
    "    'node': 10,\n",
    "}\n",
    "batch_size = {\n",
    "    'edge': -1,\n",
    "    'node': {\n",
    "        'facebook': 256,\n",
    "        'reddit':   2048,\n",
    "        'amazon':   4096,\n",
    "    }\n",
    "}\n",
    "max_grad_norm=1\n",
    "repeats=10\n",
    "logger='wandb'\n",
    "\n",
    "cmd = []\n",
    "\n",
    "cmd += CommandBuilder('gap').build(\n",
    "    name='GAP-INF',\n",
    "    dataset=dataset,\n",
    "    dp_level='edge',\n",
    "    epsilon='inf',\n",
    "    perturbation='aggr',\n",
    "    hops=hops,\n",
    "    max_degree=max_degree['edge'],\n",
    "    hidden_dim=hidden_dim,\n",
    "    encoder_layers=encoder_layers,\n",
    "    pre_layers=pre_layers,\n",
    "    post_layers=post_layers,\n",
    "    combine=combine,\n",
    "    activation=activation,\n",
    "    dropout=dropout,\n",
    "    batch_norm=batch_norm,\n",
    "    optimizer=optimizer,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    pre_epochs=pre_epochs['edge'],\n",
    "    epochs=epochs['edge'],\n",
    "    batch_size=batch_size['edge'],\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    repeats=repeats,\n",
    "    project=wandb_project,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "cmd += CommandBuilder('gap').build(\n",
    "    name='GAP-EDP',\n",
    "    dataset=dataset,\n",
    "    dp_level='edge',\n",
    "    epsilon=epsilon['edge'],\n",
    "    perturbation='aggr',\n",
    "    hops=hops,\n",
    "    max_degree=max_degree['edge'],\n",
    "    hidden_dim=hidden_dim,\n",
    "    encoder_layers=encoder_layers,\n",
    "    pre_layers=pre_layers,\n",
    "    post_layers=post_layers,\n",
    "    combine=combine,\n",
    "    activation=activation,\n",
    "    dropout=dropout,\n",
    "    batch_norm=batch_norm,\n",
    "    optimizer=optimizer,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    pre_epochs=pre_epochs['edge'],\n",
    "    epochs=epochs['edge'],\n",
    "    batch_size=batch_size['edge'],\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    repeats=repeats,\n",
    "    project=wandb_project,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# GAP-E W/O EM\n",
    "cmd += CommandBuilder('gap').build(\n",
    "    name='GAP-EDP',\n",
    "    dataset=dataset,\n",
    "    dp_level='edge',\n",
    "    epsilon=epsilon['edge'],\n",
    "    perturbation='aggr',\n",
    "    hops=hops,\n",
    "    max_degree=max_degree['edge'],\n",
    "    hidden_dim=hidden_dim,\n",
    "    encoder_layers=0,\n",
    "    pre_layers=pre_layers,\n",
    "    post_layers=post_layers,\n",
    "    combine=combine,\n",
    "    activation=activation,\n",
    "    dropout=dropout,\n",
    "    batch_norm=batch_norm,\n",
    "    optimizer=optimizer,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    pre_epochs=0,\n",
    "    epochs=epochs['edge'],\n",
    "    batch_size=batch_size['edge'],\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    repeats=repeats,\n",
    "    project=wandb_project,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "\n",
    "cmd += CommandBuilder('gap').build(\n",
    "    name='MLP',\n",
    "    dataset=dataset,\n",
    "    dp_level='edge',\n",
    "    epsilon=0,\n",
    "    perturbation='aggr',\n",
    "    hops=0,\n",
    "    max_degree=max_degree['edge'],\n",
    "    hidden_dim=hidden_dim,\n",
    "    encoder_layers=0,\n",
    "    pre_layers=encoder_layers,\n",
    "    post_layers=post_layers,\n",
    "    combine=combine,\n",
    "    activation=activation,\n",
    "    dropout=dropout,\n",
    "    batch_norm=batch_norm,\n",
    "    optimizer=optimizer,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    pre_epochs=0,\n",
    "    epochs=epochs['edge'],\n",
    "    batch_size=batch_size['edge'],\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    repeats=repeats,\n",
    "    project=wandb_project,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "cmd += CommandBuilder('sage').build(\n",
    "    name='SAGE-EDP',\n",
    "    dataset=dataset,\n",
    "    dp_level='edge',\n",
    "    epsilon=epsilon['edge'],\n",
    "    max_degree=max_degree['edge'],\n",
    "    hidden_dim=hidden_dim,\n",
    "    encoder_layers=encoder_layers,\n",
    "    mp_layers=hops,\n",
    "    post_layers=post_layers,\n",
    "    activation=activation,\n",
    "    dropout=dropout,\n",
    "    batch_norm=batch_norm,\n",
    "    optimizer=optimizer,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    epochs=epochs['edge'],\n",
    "    batch_size=batch_size['edge'],\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    repeats=repeats,\n",
    "    project=wandb_project,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "cmd += CommandBuilder('sage').build(\n",
    "    name='SAGE-INF',\n",
    "    dataset=dataset,\n",
    "    dp_level='edge',\n",
    "    epsilon='inf',\n",
    "    max_degree=max_degree['edge'],\n",
    "    hidden_dim=hidden_dim,\n",
    "    encoder_layers=encoder_layers,\n",
    "    mp_layers=hops,\n",
    "    post_layers=post_layers,\n",
    "    activation=activation,\n",
    "    dropout=dropout,\n",
    "    batch_norm=batch_norm,\n",
    "    optimizer=optimizer,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    epochs=epochs['edge'],\n",
    "    batch_size=batch_size['edge'],\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    repeats=repeats,\n",
    "    project=wandb_project,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "for dataset_name in dataset:\n",
    "    cmd += CommandBuilder('gap').build(\n",
    "        name='GAP-NDP',\n",
    "        dataset=dataset_name,\n",
    "        dp_level='node',\n",
    "        epsilon=epsilon['node'],\n",
    "        perturbation='aggr',\n",
    "        hops=hops,\n",
    "        max_degree=max_degree['node'][dataset_name]['extended'],\n",
    "        hidden_dim=hidden_dim,\n",
    "        encoder_layers=encoder_layers,\n",
    "        pre_layers=pre_layers,\n",
    "        post_layers=post_layers,\n",
    "        combine=combine,\n",
    "        activation=activation,\n",
    "        dropout=dropout,\n",
    "        batch_norm=False,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        pre_epochs=pre_epochs['node'],\n",
    "        epochs=epochs['node'],\n",
    "        batch_size=batch_size['node'][dataset_name],\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        repeats=repeats,\n",
    "        project=wandb_project,\n",
    "        logger=logger\n",
    "    )\n",
    "    \n",
    "    # GAP-N W/O EM\n",
    "    cmd += CommandBuilder('gap').build(\n",
    "        name='GAP-NDP',\n",
    "        dataset=dataset_name,\n",
    "        dp_level='node',\n",
    "        epsilon=epsilon['node'],\n",
    "        perturbation='aggr',\n",
    "        hops=hops,\n",
    "        max_degree=max_degree['node'][dataset_name]['standard'],\n",
    "        hidden_dim=hidden_dim,\n",
    "        encoder_layers=0,\n",
    "        pre_layers=pre_layers,\n",
    "        post_layers=post_layers,\n",
    "        combine=combine,\n",
    "        activation=activation,\n",
    "        dropout=dropout,\n",
    "        batch_norm=False,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        pre_epochs=0,\n",
    "        epochs=epochs['node'],\n",
    "        batch_size=batch_size['node'][dataset_name],\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        repeats=repeats,\n",
    "        project=wandb_project,\n",
    "        logger=logger\n",
    "    )\n",
    "    \n",
    "    cmd += CommandBuilder('sage').build(\n",
    "        name='SAGE-NDP',\n",
    "        dataset=dataset_name,\n",
    "        dp_level='node',\n",
    "        epsilon=epsilon['node'],\n",
    "        max_degree=max_degree['node'][dataset_name]['standard'],\n",
    "        hidden_dim=hidden_dim,\n",
    "        encoder_layers=encoder_layers,\n",
    "        mp_layers=1,\n",
    "        post_layers=post_layers,\n",
    "        activation=activation,\n",
    "        dropout=dropout,\n",
    "        batch_norm=False,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        epochs=epochs['node'],\n",
    "        batch_size=batch_size['node'][dataset_name],\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        repeats=repeats,\n",
    "        project=wandb_project,\n",
    "        logger=logger\n",
    "    )\n",
    "\n",
    "    cmd += CommandBuilder('gap').build(\n",
    "        name='MLP-DP',\n",
    "        dataset=dataset_name,\n",
    "        dp_level='node',\n",
    "        epsilon=epsilon['node'],\n",
    "        perturbation='aggr',\n",
    "        hops=0,\n",
    "        max_degree=-1,\n",
    "        hidden_dim=hidden_dim,\n",
    "        encoder_layers=0,\n",
    "        pre_layers=encoder_layers,\n",
    "        post_layers=post_layers,\n",
    "        combine=combine,\n",
    "        activation=activation,\n",
    "        dropout=dropout,\n",
    "        batch_norm=False,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        pre_epochs=0,\n",
    "        epochs=epochs['node'],\n",
    "        batch_size=batch_size['node'][dataset_name],\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        repeats=repeats,\n",
    "        project=wandb_project,\n",
    "        logger=logger\n",
    "    )\n",
    "\n",
    "\n",
    "shuffle(cmd)\n",
    "\n",
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{wandb_user}/{wandb_project}\")\n",
    "run_cmds = []\n",
    "\n",
    "try:\n",
    "    for run in track(runs, description='Fetching finished runs...'): \n",
    "        command = 'python ' + run.config['cmd']\n",
    "        command = ' '.join(command.split())\n",
    "        run_cmds.append(command)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "        \n",
    "new_cmd = set(cmd) - set(run_cmds)\n",
    "num_total = len(cmd)\n",
    "num_finished = len(run_cmds)\n",
    "num_new = len(new_cmd)\n",
    "\n",
    "filename = 'jobs/gap.jobs'\n",
    "os.makedirs('jobs', exist_ok=True)\n",
    "with open(filename, 'w') as file:\n",
    "    for item in track(new_cmd):\n",
    "        print(item, file=file)\n",
    "\n",
    "print('total runs: ', num_total)\n",
    "print('finished:   ', num_finished)\n",
    "print('new:        ', num_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
