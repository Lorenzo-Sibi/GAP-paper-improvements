{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-lwvmg3c4 because the default path (/idiap/home/sajadmanesh/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from data import Dataset\n",
    "from privacy import LaplaceMechanism\n",
    "from rich.progress import track\n",
    "from torch_sparse import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class AsymmetricRandResponse:\n",
    "    def __init__(self, eps):\n",
    "        self.eps_link = eps * 0.9\n",
    "        self.eps_density = eps * 0.1\n",
    "        \n",
    "    def arr(self, data: SparseTensor):\n",
    "        n = data.size(1)\n",
    "        sensitivity = 1 / (n*n)\n",
    "        p = 1 / (1 + math.exp(-self.eps_link))\n",
    "        d = np.random.laplace(loc=data.density(), scale=sensitivity/self.eps_density)\n",
    "        q = d / (2*p*d - p - d + 1)\n",
    "        q = min(1, q)\n",
    "        pr_1to1 = p * q\n",
    "        pr_0to1 = (1 - p) * q\n",
    "        mask = data.to_dense(dtype=bool)\n",
    "        out = mask * pr_1to1 + (~mask) * pr_0to1\n",
    "        torch.bernoulli(out, out=out)\n",
    "        out = SparseTensor.from_dense(out, has_value=False)\n",
    "        return out\n",
    "\n",
    "    def __call__(self, data, chunk_size=1000):\n",
    "        chunks = self.split_sparse(data, chunk_size=chunk_size)\n",
    "        pert_chunks = []\n",
    "\n",
    "        for chunk in chunks:    \n",
    "            chunk_pert = self.arr(chunk)\n",
    "            pert_chunks.append(chunk_pert)\n",
    "\n",
    "        data_pert = self.merge_sparse(pert_chunks, chunk_size=chunk_size)\n",
    "        return data_pert\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_sparse(mat, chunk_size):\n",
    "        chunks = []\n",
    "        for i in range(0, mat.size(0), chunk_size):\n",
    "            if (i + chunk_size) <= mat.size(0):\n",
    "                chunks.append(mat[i:i+chunk_size])\n",
    "            else:\n",
    "                chunks.append(mat[i:])\n",
    "        return chunks\n",
    "    \n",
    "    @staticmethod\n",
    "    def merge_sparse(chunks, chunk_size):\n",
    "        n = (len(chunks) - 1) * chunk_size + chunks[-1].size(0)\n",
    "        m = chunks[0].size(1)\n",
    "        row = torch.cat([chunk.coo()[0] + i * chunk_size for i, chunk in enumerate(chunks)])\n",
    "        col = torch.cat([chunk.coo()[1] for chunk in chunks])\n",
    "        out = SparseTensor(row=row, col=col, sparse_sizes=(n, m))#.coalesce()\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'facebook'\n",
    "device = 'cuda'\n",
    "chunk_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...done in 0.43s\n"
     ]
    }
   ],
   "source": [
    "print('loading dataset...', end='')\n",
    "time_start = time()    \n",
    "data = Dataset(dataset, data_dir='../datasets').load()\n",
    "adj_t = data.adj_t\n",
    "time_end = time()\n",
    "print(f'done in {time_end - time_start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving data to cuda...done in 2.07s\n",
      "max GPU memory used = 0.10 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'moving data to {device}...', end='')\n",
    "time_start = time()\n",
    "data = data.to(device)\n",
    "adj_t = data.adj_t\n",
    "time_end = time()\n",
    "print(f'done in {time_end - time_start:.2f}s')\n",
    "gpu_mem = torch.cuda.max_memory_allocated() / 1024 ** 3\n",
    "print(f'max GPU memory used = {gpu_mem:.2f} GB\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturbing data...done in 0.06s\n",
      "max GPU memory used = 0.50 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'perturbing data...', end='')\n",
    "time_start = time()\n",
    "\n",
    "mech = AsymmetricRandResponse(eps=1)\n",
    "adj_t_pert = mech(adj_t, chunk_size=chunk_size)\n",
    "\n",
    "time_end = time()\n",
    "print(f'done in {time_end - time_start:.2f}s')\n",
    "gpu_mem = torch.cuda.max_memory_allocated() / 1024 ** 3\n",
    "print(f'max GPU memory used = {gpu_mem:.2f} GB\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1690ba48bac90b79f9fd48f79bebd053e96f578825c64a887e5d9c95b0e7c0e7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
